{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Applications (on Image and Video)\n",
    "- Using OpenCV and Google's tesseract\n",
    "- Practitioner: VAIBHAV HASWANI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) ON IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "i'have downloaded the OCR engine from https://github.com/UB-Mannheim/tesseract/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "#defining path to tesseract OCR engine command line executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "\n",
    "i'hv used Simple Binary Thresholding and OSTU binarization\n",
    "\n",
    "*Simple Binary thresholding*: finds a threshold and set the image color white if < threshold and black if > threshold\n",
    "\n",
    "*OSTU thresholding*: automatically picks a threshold for image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('./Data/sample4.jpg')                                                   #reading image\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                                   #Converting to GRAY scale as\n",
    "binary_img=cv2.threshold(gray_img,0,255,cv2.THRESH_OTSU | cv2.THRESH_BINARY)[1] #Performing simple thresholding with OTSU binarization\n",
    "cv2.imshow('threshold image',binary_img)                                        #Opening binary image\n",
    "cv2.waitKey(0)                                                                  #Exit at pressing any key\n",
    "cv2.destroyAllWindows()                                                         #destroying windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom configurations\n",
    "\n",
    "* --psm: Specify page segmentation mode.\n",
    "* --oem: Specify OCR Engine mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', 'This', 'is', 'SAMPLE', 'TEXT', '', 'Text', 'is', 'at', 'different', 'regions']\n"
     ]
    }
   ],
   "source": [
    "custom_config = r'--oem 3 --psm 6'                                              #Addind oem and psm to custom config\n",
    "img_info=pytesseract.image_to_data(binary_img,output_type=pytesseract.Output.DICT,config=custom_config,lang='eng')  #Getting image data from tesseract\n",
    "print(img_info['text'])                                                         #getting text info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying text in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=img.copy()\n",
    "total_boxes = len(img_info['text'])    #length of total no of blocks detected\n",
    "for sequence_number in range(total_boxes):                                        #Looping through blocks\n",
    "    if int(img_info['conf'][sequence_number])>30:                               #if confidence of box being text if greater than 30 (30-40 is optimal limit)\n",
    "        (x, y, w, h) = (img_info['left'][sequence_number], img_info['top'][sequence_number], img_info['width'][sequence_number],  img_info['height'][sequence_number])  #get the coordinates of confident blocks\n",
    "        im = cv2.rectangle(im, (x, y), (x + w, y + h), (0,255, 0), 1)     #Drawing a rectangle box over confident word\n",
    "cv2.imshow('identified text',im)                                         #Showing final image\n",
    "cv2.waitKey(0)                                                                   #Press any key to exit\n",
    "cv2.destroyAllWindows()                                                          #destroy windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(data):\n",
    "    '''Function to parse data from detected text'''\n",
    "    parsed=[]\n",
    "    last_word=''\n",
    "    for word in data:\n",
    "        if word!='':\n",
    "            parsed.append(word)\n",
    "            last_word=word\n",
    "        if last_word!='' and word=='':\n",
    "            parsed.append('\\n')\n",
    "\n",
    "    return \" \".join(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is SAMPLE TEXT \\n Text is at different regions'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=parse(img_info['text'])\n",
    "file=open('./image_data.txt','a')\n",
    "file.write(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Applications (on Image and Video)\n",
    "- Using OpenCV and Google's tesseract\n",
    "- Practitioner: VAIBHAV HASWANI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ON VIDEO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "#defining path to tesseract OCR engine command line executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture('./Data/Example_for_OCR3.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data={}\n",
    "def video_parser(time,data):\n",
    "    '''Parse Data'''\n",
    "    if data!='' and time not in parsed_data.keys():\n",
    "        if data not in parsed_data.values():\n",
    "            parsed_data[time]=data\n",
    "\n",
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "def parse(data):\n",
    "    '''Function to parse data from detected text'''\n",
    "    not_nes=['\\\\','/','!','~','`','|','-','=']\n",
    "    parsed=[]\n",
    "    last_word=''\n",
    "    for word in data:\n",
    "        if word!='' and word not in not_nes:\n",
    "            parsed.append(word)\n",
    "            last_word=word\n",
    "\n",
    "    return \" \".join(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = r'--oem 1 --psm 6' \n",
    "start=time.time()# Start Time\n",
    "\n",
    "while True:\n",
    "    ret,frame=video.read()                               #Getting video frame\n",
    "   # frame=rescale_frame(frame)\n",
    "    now=round(time.time()-start)                         #Getting current time\n",
    "    if ret:\n",
    "        gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #Converting to GRAY scale as\n",
    "        binary_frame=cv2.threshold(gray_frame,0,255,cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)[1] #Performing simple thresholding with OTSU binarization\n",
    "        frame_info=pytesseract.image_to_data(binary_frame,output_type=pytesseract.Output.DICT,config=custom_config,lang='eng')\n",
    "        fm=frame.copy()\n",
    "        total_boxes = len(frame_info['text'])    #length of total no of blocks detected\n",
    "        for sequence_number in range(total_boxes):                                        #Looping through blocks\n",
    "            if int(frame_info['conf'][sequence_number])>30:                               #if confidence of box being text if greater than 30 (30-40 is optimal limit)\n",
    "                (x, y, w, h) = (frame_info['left'][sequence_number], frame_info['top'][sequence_number], frame_info['width'][sequence_number],  frame_info['height'][sequence_number])  #get the coordinates of confident blocks\n",
    "                fm = cv2.rectangle(fm, (x, y), (x + w, y + h), (0,255, 0), 1)     #Drawing a rectangle box over confident word\n",
    "        parsed=parse(frame_info['text'])\n",
    "        video_parser(now,parsed)\n",
    "        cv2.imshow('identified text ~Exit:esc~',fm)\n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello i am Vaibhav Haswani</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Data\n",
       "1  Hello i am Vaibhav Haswani"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(parsed_data,index=['Data']).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./video_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
